{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba757e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(100, 999), (123, 765), (123, 812), (458, 123), (458, 765), (458, 812)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets to tuple method\n",
    "similar_ids = { \n",
    "    123: [458, 812, 765], \n",
    "    458: [123, 812, 765], \n",
    "    812: [123, 458], \n",
    "    765: [123, 458], \n",
    "    999: [100], \n",
    "    100: [999] \n",
    "}\n",
    "\n",
    "# Initialize set data object, Sets have unique elements \n",
    "# if try to add an element that already exist will auto-removed from set because have same hash\n",
    "result_set=set()\n",
    "\n",
    "# Get all possible pairs\n",
    "for article_from_i, articles_to_i in similar_ids.items():\n",
    "    for article_to_j in articles_to_i:\n",
    "        # Add every article from and article to pair by a set and get default ordered \n",
    "        # by set creation. and finally create a tuple because set is a unhashable type\n",
    "        result_set.add(tuple({article_from_i, article_to_j}))\n",
    "\n",
    "result_set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7edbc5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(100, 999), (123, 458), (123, 765), (123, 812), (458, 765), (458, 812)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order low to high method\n",
    "similar_ids = { \n",
    "    123: [458, 812, 765], \n",
    "    458: [123, 812, 765], \n",
    "    812: [123, 458], \n",
    "    765: [123, 458], \n",
    "    999: [100], \n",
    "    100: [999] \n",
    "}\n",
    "\n",
    "# Initialize set data object, Sets have unique elements \n",
    "# if try to add an element that already exist will auto-removed from set because have same hash\n",
    "result_set=set()\n",
    "\n",
    "# Get all possible pairs\n",
    "for article_from_i, articles_to_i in similar_ids.items():\n",
    "    for article_to_j in articles_to_i:\n",
    "        values=(\n",
    "            (article_from_i, article_to_j) \n",
    "            if article_from_i <= article_to_j \n",
    "            else \n",
    "            (article_to_j, article_from_i)\n",
    "        )\n",
    "        # Add every article from and article to pair by evaluate id value \n",
    "        # if article_from_i is lesser than article_to_j (article_from_i, article_to_j) \n",
    "        # otherwise (article_to_j, article_from_i)\n",
    "        result_set.add(values)\n",
    "\n",
    "result_set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19f3b6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Online Mode Load required functions\n",
    "import requests\n",
    "import ast\n",
    "\n",
    "\n",
    "def get_similar_articles_ids(article_id:int):\n",
    "    # Part of result of HTML where shows full id query (scrapping)\n",
    "    # Example\n",
    "    # <meta name=\"log_displayeduids\" content=\"33400058,33781287,33128197,34369712,33272178,32889088,33034824,33779135,34356617,32997322\" />\n",
    "    begin_query_str=\"<meta name=\\\"log_displayeduids\\\" content=\\\"\"\n",
    "    end_query_str=\"\\\" />\"\n",
    "\n",
    "    url=f\"https://pubmed.ncbi.nlm.nih.gov/?linkname=pubmed_pubmed&from_uid={article_id}\"\n",
    "    request_obj=requests.get(url=url)\n",
    "    \n",
    "    request_str=request_obj.text\n",
    "    partial_result=request_str[request_str.index(begin_query_str)+len(begin_query_str):]\n",
    "    ids_str=partial_result[:partial_result.index(end_query_str)]\n",
    "    return ast.literal_eval(ids_str)\n",
    "\n",
    "\n",
    "def extract_unique_ordered_pairs(related_ids):\n",
    "    # Initialize set data object, Sets have unique elements \n",
    "    # if try to add an element that already exist will auto-removed from set because have same hash\n",
    "    result_set=set()\n",
    "\n",
    "    # Get all possible pairs\n",
    "    for article_from_i, articles_to_i in related_ids.items():\n",
    "        for article_to_j in articles_to_i:\n",
    "            values=(\n",
    "                (article_from_i, article_to_j) \n",
    "                if article_from_i <= article_to_j \n",
    "                else \n",
    "                (article_to_j, article_from_i)\n",
    "            )\n",
    "            # Add every article from and article to pair by evaluate id value \n",
    "            # if article_from_i is lesser than article_to_j (article_from_i, article_to_j) \n",
    "            # otherwise (article_to_j, article_from_i)\n",
    "            result_set.add(values)\n",
    "    return result_set\n",
    "\n",
    "print(\"OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1168172d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(32307245, 33128197),\n",
       " (32336723, 33128197),\n",
       " (32416679, 33781287),\n",
       " (32791241, 34369712),\n",
       " (32830930, 33781287),\n",
       " (32889088, 33400058),\n",
       " (32997322, 33128197),\n",
       " (32997322, 33400058),\n",
       " (33034824, 33400058),\n",
       " (33112236, 33781287),\n",
       " (33128197, 33128197),\n",
       " (33128197, 33305554),\n",
       " (33128197, 33308510),\n",
       " (33128197, 33319627),\n",
       " (33128197, 33336780),\n",
       " (33128197, 33400058),\n",
       " (33128197, 33555378),\n",
       " (33128197, 33687358),\n",
       " (33128197, 34369712),\n",
       " (33132205, 33781287),\n",
       " (33249077, 33781287),\n",
       " (33272178, 33400058),\n",
       " (33272178, 34369712),\n",
       " (33319627, 34369712),\n",
       " (33362758, 34369712),\n",
       " (33400058, 33400058),\n",
       " (33400058, 33779135),\n",
       " (33400058, 33781287),\n",
       " (33400058, 34356617),\n",
       " (33400058, 34369712),\n",
       " (33676349, 34369712),\n",
       " (33781287, 33781287),\n",
       " (33781287, 33917481),\n",
       " (33781287, 34311539),\n",
       " (33781287, 34378968),\n",
       " (33781287, 35632703),\n",
       " (34276652, 34369712),\n",
       " (34356617, 34369712),\n",
       " (34369712, 34369712)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example \"online\"\n",
    "# Id of article that will get all another similar articles\n",
    "main_article_id=33400058\n",
    "\n",
    "similar_ids_list=get_similar_articles_ids(main_article_id)\n",
    "\n",
    "# Initialize dict\n",
    "similar_ids={\n",
    "    main_article_id:similar_ids_list,\n",
    "}\n",
    "\n",
    "# Search nested articles\n",
    "nested_level = 3\n",
    "\n",
    "similar_ids_iter=iter(similar_ids_list)\n",
    "for i in range(nested_level):\n",
    "    similar_id_i=next(similar_ids_iter)\n",
    "    # Force to get next value\n",
    "    if (similar_id_i==main_article_id):\n",
    "        similar_id_i=next(similar_ids_iter)\n",
    "    \n",
    "    similar_ids_i_list=get_similar_articles_ids(similar_id_i)\n",
    "    similar_ids[similar_id_i]=similar_ids_i_list\n",
    "\n",
    "\n",
    "# get unique pairs\n",
    "extract_unique_ordered_pairs(similar_ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
